---
title: 'FPGA-based Acceleration for Image Classification using Vitis-AI'
date: 2023-11-03
permalink: /posts/2023/09/blog-post-5/
tags:
  - FPGA
  - Image Classification
  - Vitis-AI
---

Blog Post #5
======
A FPGA implementation for Neural Networks running on Xilinx ZCU104


In this project, we are going to implement a hardware acceleration on neural network which is modify from [1] and [2] for image classification using Vitis-AI. Compare to the CPU performance, our works showed that FPGA achieved faster execution time, higher throughput and energy efficiency.


1: Introduction 
======
<br>
Rapidly growing of complexed applications is placing high demands on data processing capabilities. Current computational system relying on CPU is low efficiency on performance and power. It fails to meet the real-time data processing requirement. In order to avoid delays, hardware accelerator is needed to speed up the execution in embedded systems. However, the common accelerator GPU has very low energy efficiency. In recent year, FPGA stands out from the crowded among different types of accelerators due to its high flexibility and energy efficiency. 



2: Related Works 
======
<br>
There are 3 common methods to accelerate CNN using FPGA: <br>
1.  Method of hardware description language (HDL) [3] <br>
2.  Method of high-level synthesis (HLS [4] <br>
3.  Method of Vitis-AI [5] <br>

And in this project, we are going to use Vitis-AI since it is a comprehensive framework from Xilinx that support python-based CNN model. We can deploy our whole model into the ZCU104 to make the acceleration. <br>

![](/images/post5-1.png)
<br> Our CNN structure <br>

3: Accelerator Design Flow
======
<br>

![](/images/post5-2.png)
<br> Flow map & training parameters <br>

1.  Training <br>
To train our CNN model with [Cifar10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset for image classification. We will also get the performance of the model in CPU in this stage<br>
2.  Quantization <br>
To quantize our pretrained model from fp32 into int8 since the Xilinx ZCU104 DPU family execute the model in integer format. <br>
3.  Compilation <br>
To compile the model into .xmodel which is then deployed into ZCU104. <br>
4.  Evaluation on board. <br>
To leverage DPU from ZCU104 for accelerating the model, such as pipelining. We will get the performance from FPGA and finally make the comparison. <br>


4: Results
======
<br>

We will use the following metrics to evaluate the acceleration on ZCU104. <br>

Accuracy is defined as the percentage of correct predictions made by the model over the whole dataset. <br>
Latency is defined as the total forward time for the model to make predictions over the whole dataset. <br>
Throughput is defined as the number of predictions produced by the model in a given amount of time. The unit is frame per second (fps) and the formula is shown as the following: <br>
Throughput  =  length of dataset / latency <br>

![](/images/post5-3.png)
<br> ZCU104 evaluation board

![](/images/post5-4.png)
<br> FPGA performance with different threads

![](/images/post5-5.png)
<br> Comparision between CPU & FPGA

![](/images/post5-6.png)
<br> Further comparision with relavant works

<br>
In conclusion, as we can see that, the FPGA achieved around 10x faster in terms of execution time, and 10x higher in terms of throughgput and energy efficiency. and compare to other related works [6] [7], our project achieved the highest throughput in FPGA. 
<br>

5: Conclusion
======
<br>

We implemented a FPGA-based acceleration on proposed CNN network on ZCU104. We leverage the DPU from Vitis-AI to speedup data processing for the nerual network, achieving faster time, higher throughput and energy efficiency. In the future work, we will perform similar tricks on 3D reconstrcution, like speeding up depth map estimation from monocular camera. 
<br>

Hope you enjoy this :)

Reference:<br>
<br>[1] Hong, Z., & Yue, C. P. (2023). Cross-Dimensional Refined Learning for Real-Time 3D Visual Perception from Monocular Video. arXiv preprint arXiv:2303.09248.
<br>[2] https://github.com/AnjieCheng/MnasNet-PyTorch/blob/master/MnasNet.py 
<br>[3] Guan, Y., Sun, G., Yuan, Z., Li, X., Xu, N., Chen, S., ... & Xie, Y. (2020). Crane: Mitigating accelerator under-utilization caused by sparsity irregularities in cnns. IEEE Transactions on Computers, 69(7), 931-943. 
<br>[4] Liu, Z., Chow, P., Xu, J., Jiang, J., Dou, Y., & Zhou, J. (2019). A uniform architecture design for accelerating 2D and 3D CNNs on FPGAs. Electronics, 8(1), 65.
<br>[5] Wang, J., & Gu, S. (2021, May). Fpga implementation of object detection accelerator based on vitis-ai. In 2021 11th International Conference on Information Science and Technology (ICIST) (pp. 571-577). IEEE.
<br>[6] ÄŒech, J., & Rozkovec, M. (2021, September). Comparison of performance of optimized HSI CNN models on desktop and embedded platforms. In 2021 International Conference on Applied Electronics (AE) (pp. 1-4). IEEE. 
<br>[7] Berzoini, R., D'Arnese, E., & Conficconi, D. (2022, May). On how to push efficient medical semantic segmentation to the edge: the seneca approach. In 2022 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW) (pp. 104-111). IEEE. 